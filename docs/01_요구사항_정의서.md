# RAG 기반 개인용 생성형 AI 챗봇 - 요구사항 정의서

## 1. 개요
본 문서는 초보 개발자들을 위한 "RAG 기반 개인용 생성형 AI 챗봇" 시스템의 요구사항을 정의합니다. 이 시스템은 사용자가 개인 PC에 저장된 문서 파일을 업로드하고, 해당 문서를 기반으로 질의응답을 수행할 수 있는 챗봇 서비스를 제공합니다.

## 2. 개발 환경
- 프로젝트명: my_rag_chat
- OS: Windows 10 또는 11
- 개발 IDE: VS Code 또는 Windsurf
- Python 버전: 3.11.11
- 가상환경: Miniconda (환경명: my_rag)

## 3. 주요 구성 요소
- 벡터스토어: Faiss-cpu (version 1.10.0)
- 임베딩 모델: 허깅페이스의 jhgan/ko-sroberta-multitask
- 주요 패키지: huggingface-hub(0.30.1), Langchain(0.3.22)
- 파일 등록 대시보드: Dash (version 3.0.2)
- 챗팅창: Chainlit 기반 (version 2.4.400)
- LLM 서비스: 
  - LM Studio 기반 API (Stream 모드 사용)
  - Google Gemini API (Stream 모드 사용)

## 4. 기능 요구사항

### 4.1 파일 등록 대시보드
- **FR-1.1**: 사용자는 대시보드에 접속하여 문서 파일을 업로드할 수 있어야 한다.
- **FR-1.2**: 지원되는 파일 형식은 txt, md, pdf, docx, eml이다.
- **FR-1.3**: 업로드된 파일은 자동으로 청킹(chunking)되어 벡터스토어 DB에 저장되어야 한다.
- **FR-1.4**: 사용자는 업로드된 파일 목록을 확인할 수 있어야 한다.
- **FR-1.5**: 사용자는 업로드된 파일을 삭제할 수 있어야 한다.
- **FR-1.6**: 한글 파일명 처리가 가능해야 한다.
- **FR-1.7**: EML 파일에서 이메일 메타데이터, 본문 및 첨부파일 정보를 추출할 수 있어야 한다.

### 4.2 챗팅창
- **FR-2.1**: 사용자는 챗팅창에 접속하여 질문을 입력할 수 있어야 한다.
- **FR-2.2**: 시스템은 사용자 질문을 분석하여 관련된 문서를 벡터스토어에서 검색해야 한다.
- **FR-2.3**: 시스템은 검색된 문서와 사용자 질문을 LLM에 전달하여 응답을 생성해야 한다.
- **FR-2.4**: 응답은 스트리밍 방식으로 사용자에게 실시간으로 제공되어야 한다.
- **FR-2.5**: 스트리밍 과정에서 매 토큰이 생성될 때마다 화면에 즉시 표시되어야 한다.
- **FR-2.6**: 사용자는 대화 내역을 확인할 수 있어야 한다.
- **FR-2.7**: 사용자는 새로운 대화를 시작할 수 있어야 한다.
- **FR-2.8**: 검색된 관련 문서의 목록과 관련성 점수가 답변과 함께 표시되어야 한다.
- **FR-2.9**: 사용자는 LM Studio와 Google Gemini 중 원하는 LLM 서비스를 선택할 수 있어야 한다.

## 5. 비기능 요구사항

### 5.1 성능
- **NFR-1.1**: 파일 업로드 후 벡터스토어 DB에 저장되는 시간은 파일 크기에 따라 다르지만, 일반적인 문서(~10MB)의 경우 30초 이내여야 한다.
- **NFR-1.2**: 사용자 질문 입력 후 응답 시작까지의 지연 시간은 3초 이내여야 한다.
- **NFR-1.3**: 스트리밍 모드에서는 첫 토큰이 표시되기 시작한 후 자연스러운 속도로 토큰들이 화면에 나타나야 한다.
- **NFR-1.4**: 검색 정확도를 위해 청킹 사이즈는 적절하게 설정되어야 한다.

### 5.2 보안
- **NFR-2.1**: 모든 데이터는 로컬 PC에서만 처리되어야 한다. (외부 서버로 전송 금지)
- **NFR-2.2**: LLM API 키 정보는 환경 변수나 구성 파일에 안전하게 저장되어야 한다.

### 5.3 사용성
- **NFR-3.1**: 인터페이스는 직관적이고 초보자도 쉽게 사용할 수 있어야 한다.
- **NFR-3.2**: 오류 메시지는 명확하고 사용자가 이해하기 쉬워야 한다.
- **NFR-3.3**: 시스템의 현재 상태(파일 업로드 중, 청킹 중, 응답 생성 중 등)가 사용자에게 시각적으로 표시되어야 한다.

### 5.4 확장성
- **NFR-4.1**: 다양한 유형의 문서 형식을 추가할 수 있는 구조여야 한다.
- **NFR-4.2**: 다양한 LLM 모델을 교체하여 사용할 수 있어야 한다.
- **NFR-4.3**: 임베딩 모델을 교체하여 사용할 수 있어야 한다.
- **NFR-4.4**: 다양한 LLM 서비스(LM Studio, Google Gemini, OpenAI 등)를 추가 및 교체할 수 있는 인터페이스를 제공해야 한다.

### 5.5 유지 보수성
- **NFR-5.1**: 코드는 명확한 주석과 문서화로 초보자도 이해할 수 있어야 한다.
- **NFR-5.2**: 모듈화된 구조로 개별 구성 요소 교체가 용이해야 한다.
- **NFR-5.3**: 로깅 시스템을 통해 문제 진단이 용이해야 한다.

## 6. 제약 사항
- **CON-1**: 시스템은 Windows 10 또는 11 환경에서 실행되어야 한다.
- **CON-2**: Python 3.11.11 버전에서 동작해야 한다.
- **CON-3**: 단일 PC에서 모든 기능이 동작해야 한다.
- **CON-4**: LM Studio API 및 Google Gemini API를 사용하여 LLM 서비스를 제공해야 한다.

## 7. 가정 및 의존성
- **ASM-1**: 사용자 PC에 LM Studio가 설치되어 있고, API 서비스가 실행 중이다.
- **ASM-2**: 사용자 PC에 충분한 메모리와 저장 공간이 있다.
- **ASM-3**: 사용자 PC에 Miniconda가 설치되어 있고, 필요한 가상 환경이 구성되어 있다.
- **ASM-4**: Gemini API 사용을 위한 API 키가 제공된다.
- **ASM-5**: 이메일 파일(EML) 처리를 위한 beautifulsoup4 라이브러리가 설치되어 있다.
